{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60292e1a",
   "metadata": {},
   "source": [
    "1 \n",
    "\n",
    "1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "50bfaa60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:/Users/Alexandre/Documents/GitHub/si/src\")\n",
    "from si.io.csv_file import read_csv\n",
    "from si.data.dataset import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dataset_iris = read_csv(r\"C:/Users/Alexandre/Documents/GitHub/si/datasets/iris/iris.csv\", features=True, label=True )\n",
    "dataset_iris.shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f00447",
   "metadata": {},
   "source": [
    "1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ea50423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'petal_length'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_iris.features[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "398ea032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penultima_var=dataset_iris.X[:,-2]\n",
    "penultima_var.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc676a5f",
   "metadata": {},
   "source": [
    "1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "678392d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal_length: 6.45\n",
      "sepal_width: 3.03\n",
      "petal_length: 5.33\n",
      "petal_width: 2.17\n"
     ]
    }
   ],
   "source": [
    "last_ten = dataset_iris.X[-10:,:]\n",
    "for i in range(len(dataset_iris.features)):\n",
    "    array=last_ten[:,i]\n",
    "    print(f'{dataset_iris.features[i]}: {round(array.mean(),3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2307719",
   "metadata": {},
   "source": [
    "1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b413a1c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples=[]\n",
    "for sample in dataset_iris.X:\n",
    "   if np.all(sample<=6):\n",
    "      samples.append(sample)\n",
    "len(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117d5bd1",
   "metadata": {},
   "source": [
    "1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a48ea92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_iris_setosa_samples=[]\n",
    "for sample in dataset_iris.y:\n",
    "    if sample != 'Iris-setosa':\n",
    "        non_iris_setosa_samples.append(sample)\n",
    "len(non_iris_setosa_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0e6fc5",
   "metadata": {},
   "source": [
    "2\n",
    "\n",
    "2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b18daa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 3.],\n",
       "       [4., 5., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from si.data.dataset import Dataset\n",
    "X = np.array([\n",
    "            [1, np.nan, 3],\n",
    "            [4, 5, np.nan]\n",
    "        ])\n",
    "dataset = Dataset(X, y=None)\n",
    "\n",
    "dataset.fillna(value=0)\n",
    "dataset.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e0e8d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 5., 6.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([\n",
    "            [1, 2, np.nan],\n",
    "            [4, 5, 6],\n",
    "            [np.nan, 1, 2]\n",
    "            ])\n",
    "y = np.array([1, 2, 3])\n",
    "dataset = Dataset(X, y)\n",
    "\n",
    "dataset.dropna()\n",
    "dataset.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "630e216e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [5, 6]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "y = np.array([10, 20, 30])\n",
    "dataset = Dataset(X, y)\n",
    "\n",
    "dataset.remove_by_index(1)\n",
    "\n",
    "dataset.X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359ff794",
   "metadata": {},
   "source": [
    "3\n",
    "\n",
    "3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c3fd180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['petal_length'], dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from si.feature_selection.select_percentile import SelectPercentile\n",
    "from si.statistics.f_classification import f_classification\n",
    "\n",
    "# percentil=25, para escolher a feature, com maior score no f_classification(oneway ANOVA)\n",
    "# 4 features -> 100% / 4 = 25%\n",
    "selector=SelectPercentile(score_func=f_classification, percentile=25)\n",
    "selector.fit(dataset_iris)\n",
    "new_dataset=selector.transform(dataset_iris)\n",
    "new_dataset.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2089cfd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-values: [ 119.26450218   47.3644614  1179.0343277   959.32440573]\n",
      "p-values: [1.66966919e-31 1.32791652e-16 3.05197580e-91 4.37695696e-85]\n"
     ]
    }
   ],
   "source": [
    "print('F-values:',selector.F)\n",
    "print('p-values:', selector.p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19922585",
   "metadata": {},
   "source": [
    "4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6649e701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5, 0.6666666666666666, 0.6666666666666666]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from si.statistics.tanimoto_similarity import tanimoto_similarity\n",
    "x = [1,0,1,1]\n",
    "y = [\n",
    "    [1,1,0,1],\n",
    "    [0,0,1,1],\n",
    "    [1,0,1,0]\n",
    "]\n",
    "\n",
    "tanimoto_similarity(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13f61e7",
   "metadata": {},
   "source": [
    "5\n",
    "\n",
    "5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "92b5f018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92461621, 0.05301557, 0.01718514, 0.00518309])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from si.decomposition.pca import PCA\n",
    "pca=PCA(n_components=4)\n",
    "pca.fit(dataset_iris)\n",
    "pca.transform(dataset_iris)\n",
    "pca.explained_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "09939eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92461621, 0.05301557, 0.01718514, 0.00518309])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA as skpca\n",
    "\n",
    "sk_pca=skpca(n_components=4)\n",
    "sk_pca.fit(dataset_iris.X)\n",
    "sk_pca.transform(dataset_iris.X)\n",
    "sk_pca.explained_variance_/sk_pca.explained_variance_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f49f4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.36158968 -0.08226889  0.85657211  0.35884393]\n",
      " [-0.65653988 -0.72971237  0.1757674   0.07470647]]\n",
      "[[ 0.36158968 -0.08226889  0.85657211  0.35884393]\n",
      " [ 0.65653988  0.72971237 -0.1757674  -0.07470647]]\n"
     ]
    }
   ],
   "source": [
    "print(pca.components)\n",
    "print(sk_pca.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bed54c",
   "metadata": {},
   "source": [
    "6\n",
    "\n",
    "6.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c9f7fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from si.model_selection.split import stratified_train_test_split\n",
    "train,test=stratified_train_test_split(dataset_iris, 0.2, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "680bfdf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(30, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train.shape())\n",
    "test.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef683440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: [0.33333333 0.33333333 0.33333333]\n",
      "Train: [0.33333333 0.33333333 0.33333333]\n",
      "Test: [0.33333333 0.33333333 0.33333333]\n",
      "Classes treino: ['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n",
      "Classes teste: ['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n"
     ]
    }
   ],
   "source": [
    "# proporções no dataset original\n",
    "unique, counts = np.unique(dataset_iris.y, return_counts=True)\n",
    "print(\"Original:\", counts / counts.sum())\n",
    "\n",
    "# proporções no treino\n",
    "u_train, c_train = np.unique(train.y, return_counts=True)\n",
    "print(\"Train:\", c_train / c_train.sum())\n",
    "\n",
    "# proporções no teste\n",
    "u_test, c_test = np.unique(test.y, return_counts=True)\n",
    "print(\"Test:\", c_test / c_test.sum())\n",
    "\n",
    "print(\"Classes treino:\", np.unique(train.y))\n",
    "print(\"Classes teste:\", np.unique(test.y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9226ec5",
   "metadata": {},
   "source": [
    "7\n",
    "\n",
    "7.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3198a884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209, 6)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from si.models.knn_regressor import KNNregressor\n",
    "dataset_cpu = read_csv(r\"C:/Users/Alexandre/Documents/GitHub/si/datasets/cpu/cpu.csv\", features=True, label=True )\n",
    "dataset_cpu.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98f34589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: [ 40.85 274.95 274.95 274.95 124.95 284.65 330.3  330.3  476.65 476.65\n",
      "  59.7   29.9   65.65  98.65  20.05  84.35  53.2   39.6   52.3   44.9 ]\n",
      "Score RMSE: 94.636\n"
     ]
    }
   ],
   "source": [
    "knnregressor=KNNregressor(k=20)\n",
    "knnregressor.fit(dataset_cpu)\n",
    "y_pred=knnregressor.predict(dataset_cpu)\n",
    "print('Preds:',y_pred[:20])\n",
    "print('Score RMSE:',knnregressor.score(dataset_cpu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d85f3390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: [ 40.85 274.95 274.95 274.95 124.95 284.65 330.3  330.3  476.65 476.65\n",
      "  59.7   29.9   65.65  99.05  20.05  84.35  53.2   39.6   52.3   44.9 ]\n",
      "Score: 0.6516698568973874\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "sk_knnregressor = KNeighborsRegressor(n_neighbors=20)\n",
    "\n",
    "# treino\n",
    "sk_knnregressor.fit(dataset_cpu.X, dataset_cpu.y)\n",
    "\n",
    "# predição (dataset completo)\n",
    "sk_pred = sk_knnregressor.predict(dataset_cpu.X)\n",
    "print('Preds:',sk_pred[:20])\n",
    "print('Score:',sk_knnregressor.score(dataset_cpu.X,dataset_cpu.y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eaa05473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn RMSE: 94.694\n"
     ]
    }
   ],
   "source": [
    "# Usando a sua função RMSE\n",
    "# O dataset.y é y_true\n",
    "# O sk_pred é y_pred\n",
    "my_rmse = knnregressor._score(dataset_cpu, sk_pred) \n",
    "print('Sklearn RMSE:', my_rmse) \n",
    "# Este valor é MUITO próximo do 94.636 (a diferença é mínima devido a arredondamentos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4460e92",
   "metadata": {},
   "source": [
    "8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d004c03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta zero (intercept): 105.61722488038275\n",
      "Theta: [12.48809072 58.902124   64.91145823 25.9868963  -1.48080797 38.23854302]\n"
     ]
    }
   ],
   "source": [
    "from si.models.ridge_regression_least_squares import RidgeRegressionLeastSquares\n",
    "\n",
    "rrls= RidgeRegressionLeastSquares(l2_penalty=1.0, scale=True)\n",
    "rrls.fit(dataset_cpu)\n",
    "print(\"Theta zero (intercept):\", rrls.theta_zero)\n",
    "print(\"Theta:\", rrls.theta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e77d8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 3478.6907903184483\n"
     ]
    }
   ],
   "source": [
    "pred_y = rrls.predict(dataset_cpu)\n",
    "pred_y[:10]   \n",
    "print(\"MSE:\", rrls.score(dataset_cpu))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "457aa65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn Intercept: 105.61722488038278\n",
      "Sklearn Scaled Coefs: [12.48809072 58.902124   64.91145823 25.9868963  -1.48080797 38.23854302]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Escalar dados para o sklearn\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(dataset_cpu.X)\n",
    "\n",
    "# Treinar Ridge com dados escalados\n",
    "ridge_scaled = Ridge(alpha=1.0)\n",
    "ridge_scaled.fit(X_scaled, dataset_cpu.y)\n",
    "\n",
    "print(\"Sklearn Intercept:\", ridge_scaled.intercept_)\n",
    "print(\"Sklearn Scaled Coefs:\", ridge_scaled.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7693fa1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My model: [337.20662835 311.31898441 311.31898441 311.31898441 198.94927755]\n",
      "Sklearn: [337.16002677 311.94414755 311.94414755 311.94414755 199.08377291]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge_sklearn = Ridge(alpha=1.0)\n",
    "ridge_sklearn.fit(dataset_cpu.X, dataset_cpu.y)\n",
    "\n",
    "print(\"My model:\", pred_y[:5])\n",
    "print(\"Sklearn:\", ridge_sklearn.predict(dataset_cpu.X)[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ffb858cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My model: [337.20662835 311.31898441 311.31898441 311.31898441 198.94927755]\n",
      "Sklearn: [337.20662835 311.31898441 311.31898441 311.31898441 198.94927755]\n"
     ]
    }
   ],
   "source": [
    "print(\"My model:\", pred_y[:5])\n",
    "print(\"Sklearn:\", ridge_scaled.predict(X_scaled)[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf37051e",
   "metadata": {},
   "source": [
    "9\n",
    "\n",
    "9.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60e46c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: ['Iris-versicolor', 'Iris-setosa', 'Iris-virginica', 'Iris-versicolor', 'Iris-versicolor', 'Iris-setosa', 'Iris-versicolor', 'Iris-virginica', 'Iris-versicolor', 'Iris-versicolor', 'Iris-virginica', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-versicolor', 'Iris-virginica', 'Iris-versicolor', 'Iris-versicolor', 'Iris-virginica', 'Iris-setosa', 'Iris-virginica', 'Iris-setosa', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-versicolor', 'Iris-setosa', 'Iris-setosa', 'Iris-virginica', 'Iris-versicolor', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-virginica', 'Iris-versicolor', 'Iris-versicolor', 'Iris-setosa', 'Iris-setosa', 'Iris-versicolor', 'Iris-versicolor', 'Iris-virginica', 'Iris-versicolor']\n",
      "Score: 0.9795918367346939\n"
     ]
    }
   ],
   "source": [
    "from si.models.random_forest_classifier import RandomForestClassifier\n",
    "from si.model_selection.split import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(dataset_iris, test_size=0.33, random_state=42)\n",
    "\n",
    "model_rf = RandomForestClassifier(\n",
    "    n_estimators=6,\n",
    "    max_features=2,       \n",
    "    min_sample_split=2,\n",
    "    max_depth=5,\n",
    "    mode=\"gini\",\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "model_rf.fit(train_set)\n",
    "predictions=model_rf.predict(test_set)\n",
    "print('Predictions:',predictions)\n",
    "print('Score:',model_rf.score(test_set))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e7687b",
   "metadata": {},
   "source": [
    "10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60b6ed02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StackingClassifier accuracy: 0.9285714285714286\n"
     ]
    }
   ],
   "source": [
    "from si.data.dataset import Dataset\n",
    "from si.io.csv_file import read_csv\n",
    "from si.models.knn_classifier import KNNClassifier\n",
    "from si.models.logistic_regression import LogisticRegression\n",
    "from si.models.decision_tree_classifier import DecisionTreeClassifier\n",
    "from si.ensemble.stacking_classifier import StackingClassifier\n",
    "from si.model_selection.split import stratified_train_test_split\n",
    "\n",
    "dataset_breast= read_csv(r\"C:/Users/Alexandre/Documents/GitHub/si/datasets/breast_bin/breast-bin.csv\", features=True, label=True )\n",
    "\n",
    "X = dataset_breast.X\n",
    "y = dataset_breast.y\n",
    "\n",
    "# 2. Dividir em treino/teste\n",
    "train_dataset, test_dataset = stratified_train_test_split(dataset_breast, test_size=0.2)\n",
    "\n",
    "# 3. Criar modelos base\n",
    "knn_1 = KNNClassifier(k=3)\n",
    "log_reg = LogisticRegression()\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "# 4. Criar modelo final\n",
    "knn_final = KNNClassifier(k=3)\n",
    "\n",
    "# 5. Criar stacking classifier\n",
    "stacking = StackingClassifier(\n",
    "    models=[knn_1, log_reg, dt],\n",
    "    final_model=knn_final\n",
    ")\n",
    "\n",
    "# 6. Treinar modelo\n",
    "stacking.fit(train_dataset)\n",
    "\n",
    "# 7. Prever no conjunto de teste\n",
    "predictions = stacking.predict(test_dataset)\n",
    "\n",
    "# 8. Calcular score\n",
    "score = stacking.score(test_dataset)\n",
    "print(\"StackingClassifier accuracy:\", score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c115d7f",
   "metadata": {},
   "source": [
    "11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f82f549e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores obtained:\n",
      "Iteration 1: 0.9684\n",
      "Iteration 2: 0.9684\n",
      "Iteration 3: 0.9670\n",
      "Iteration 4: 0.9670\n",
      "Iteration 5: 0.9670\n",
      "Iteration 6: 0.9655\n",
      "Iteration 7: 0.9670\n",
      "Iteration 8: 0.9670\n",
      "Iteration 9: 0.9670\n",
      "Iteration 10: 0.9670\n",
      "\n",
      "Best score: 0.9683908045977012\n",
      "Best hyperparameters:\n",
      "  l2_penalty: 6.0\n",
      "  alpha: 0.0004363636363636364\n",
      "  max_iter: 1376\n"
     ]
    }
   ],
   "source": [
    "from si.model_selection.randomized_search import randomized_search_cv\n",
    "from si.models.logistic_regression import LogisticRegression\n",
    "from si.metrics.accuracy import accuracy\n",
    "\n",
    "# 2. Create Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# 3. Hyperparameter distributions\n",
    "param_distributions = {\n",
    "    \"l2_penalty\": np.linspace(1, 10, 10),\n",
    "    \"alpha\": np.linspace(0.001, 0.0001, 100),\n",
    "    \"max_iter\": np.linspace(1000, 2000, 200).astype(int)\n",
    "}\n",
    "\n",
    "# 4. Randomized search\n",
    "results = randomized_search_cv(\n",
    "    model=model,\n",
    "    dataset=dataset_breast,\n",
    "    hyperparameter_grid=param_distributions,\n",
    "    scoring=accuracy,\n",
    "    cv=3,\n",
    "    n_iter=10\n",
    ")\n",
    "\n",
    "# 5. Print results\n",
    "print(\"Scores obtained:\")\n",
    "for i, score in enumerate(results[\"scores\"]):\n",
    "    print(f\"Iteration {i+1}: {score:.4f}\")\n",
    "\n",
    "print(\"\\nBest score:\", results[\"best_score\"])\n",
    "print(\"Best hyperparameters:\")\n",
    "for k, v in results[\"best_hyperparameters\"].items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
